# Pentest Documentation

### AWS EC2 Server

- Needs EC2 instance with Ubuntu, Instance type: t2.medium, 30 GB gp2 Root volume
  
  - A t2.medium instance type or better is needed to run dotCMS with docker as it needs at least 2 GB of RAM and the t2.medium has 4 GiB of memory
    
    - It was eventually upgraded to a c6i.xlarge (4 vCPUs and 8GiB memory) instance due to high intensity tools crashing the server since there wasn't enough RAM
      
  - We originally planned on using a Kali Linux EC2 instance, but the AWS Kali Linux AMI does not come with the tools preinstalled and it essentially serves as an Ubuntu instance with the only difference being that it is easier to download all of the Kali tools at once using a Kali metapackage. But since we only need a few certain tools, we are using an Ubuntu instance.
    
  - Under the inbound rules for the security group, ports 8082 & 8443 should be open
    
  - Pricing information for this task if necessary:
    
    - [https://calculator.aws/](https://calculator.aws/)

### Setup on Server

- First, install docker
  
  - [Install Docker Engine on Ubuntu | Docker Documentation](https://docs.docker.com/engine/install/ubuntu/)
    
  - You also may need to install docker-compose
    
- Follow the rest of the steps here:
  
  - [Quick Start Guide | dotCMS](https://www.dotcms.com/docs/latest/quick-start-guide)
- Set up SSH on the server with your GitHub
  
  - [Connecting to GitHub with SSH - GitHub Docs](https://docs.github.com/en/authentication/connecting-to-github-with-ssh)
    
  - Clone the repository where you will be pushing your test results using SSH
    
- Install all necessary tools for the workflow to run
  
  - Tools that I use include:
    
    - nikto
    - sslscan
  - Also need to install jq in order for the workflow to get the latest release version
    
- Set up GitHub self-hosted runner
  
  - [Adding self-hosted runners - GitHub Enterprise Cloud Docs](https://docs.github.com/en/enterprise-cloud@latest/actions/hosting-your-own-runners/managing-self-hosted-runners/adding-self-hosted-runners)
- Create htmlreport.py
  
  - Creates html writeups for the tests and creates a markdown file with githack links to the html pages with the test results
    
  - ```python
    import datetime
    import re
    import sys
    
    # Read the release version from the command-line argument
    release_version = sys.argv[1]
    
    # Generate the folder path based on the current date and release version
    folder_path = datetime.datetime.now().strftime("/home/ubuntu/core-test-results/pentest/%Y-%m-%d")
    folder_path += "-" + release_version
    
    reports_folder_path = f"dotCMS/core-test-results/{release_version}/pentest/{datetime.datetime.now().strftime('%Y-%m-%d')}"
    reports_folder_path += "-" + release_version
    # Read the content from the report.txt file
    with open(f"{folder_path}/report.txt", "r") as file:
        output = file.read()
    
    lines = output.split("\n")
    
    
    # Read the content from the sslscan_result.txt file
    with open(f"{folder_path}/sslscan_report.txt", "r") as sslscan_file:
        sslscan_output = sslscan_file.read()
    
    
    # Remove ANSI escape codes from sslscan_output
    ansi_escape = re.compile(r'\x1B\[[0-9;]*[JKmsu]')
    sslscan_output = ansi_escape.sub('', sslscan_output)
    
    start_time = ""
    end_time = ""
    section_content = ""
    section_count = 0
    
    # Extract start time, end time, and relevant content
    for line in lines:
        if line.startswith("+ Start Time:"):
            start_time = line[14:].strip()
        elif line.startswith("+ End Time:"):
            end_time = line[12:].strip()
        elif line.startswith("---"):
            section_count += 1
            if section_count == 2:
                section_content = ""
            elif section_count == 3:
                break
        elif section_count == 2:
            section_content += line.strip("+").strip() + "\n"
    
    nikto_html_output = """
    <!DOCTYPE html>
    <html>
    <head>
      <title>Nikto Scan Report</title>
      <style>
        body {{
          font-family: Arial, sans-serif;
          line-height: 1.6;
          padding: 20px;
        }}
        h1 {{
          font-size: 24px;
        }}
        h2 {{
          font-size: 20px;
        }}
        pre {{
          background-color: #f5f5f5;
          padding: 10px;
          border: 1px solid #ddd;
        }}
        ul {{
          list-style-type: disc;
          margin-top: 10px;
          margin-bottom: 10px;
        }}
        .section {{
          margin-bottom: 20px;
        }}
        .wrapped {{
          white-space: pre-wrap;
        }}
      </style>
    </head>
    <body>
      <h1>Nikto Scan Report</h1>
      <h2>Start Time: {start_time}</h2>
      <h2>End Time: {end_time}</h2>
    """
    
    # Add relevant content section
    if section_content:
        section_title = "Results:"
        section_lines = section_content.strip().split("\n")
        section_content_html = "<ul>\n"
        for line in section_lines:
            wrapped_line = line.strip()
            # Check if line contains a URL
            url_match = re.search(r"(https?://\S+)", wrapped_line)
            if url_match:
                url = url_match.group(1)
                wrapped_line = wrapped_line.replace(url, f'<a href="{url}">{url}</a>')
            section_content_html += f'  <li class="wrapped">{wrapped_line}</li>\n  <hr>\n'
        section_content_html += "</ul>"
        nikto_html_output += f'\n<div class="section">\n  <h2>{section_title}</h2>\n  <pre>{section_content_html}</pre>\n</div>'
    
    nikto_html_output += """
    </body>
    </html>
    """
    
    # Format the string placeholders with start_time and end_time
    nikto_html_output = nikto_html_output.format(start_time=start_time, end_time=end_time)
    
    # Write the HTML output to nikto_scan.html in the specified folder
    with open(f"{folder_path}/nikto_scan.html", "w") as file:
        file.write(nikto_html_output)
    
    
    # Create sslscan HTML report
    sslscan_html_output = """
    <!DOCTYPE html>
    <html>
    <head>
      <title>SSLScan Report</title>
      <style>
        /* ... (your existing style) ... */
      </style>
    </head>
    <body>
      <h1>SSLScan Report</h1>
      <h2>Start Time: {start_time}</h2>
      <h2>End Time: {end_time}</h2>
      <div class="section">
        <h2>SSLScan Results</h2>
        <pre>{sslscan_output}</pre>
      </div>
    </body>
    </html>
    """
    
    # Format the string placeholders with start_time, end_time, and sslscan_output
    sslscan_html_output = sslscan_html_output.format(start_time=start_time, end_time=end_time, sslscan_output=sslscan_output)
    
    # Write the HTML output to sslscan_report.html in the specified folder
    with open(f"{folder_path}/sslscan_report.html", "w") as file:
        file.write(sslscan_html_output)
    
    # Generate index.html in the original folder
    
    index_html_output = """
    <!DOCTYPE html>
    <html>
    <head>
      <title>Scan Reports</title>
      <style>
        body {{
          font-family: Arial, sans-serif;
          line-height: 1.6;
          padding: 20px;
        }}
        h1 {{
          font-size: 24px;
        }}
        h2 {{
          font-size: 20px;
        }}
        ul {{
          list-style-type: disc;
          margin-top: 10px;
          margin-bottom: 10px;
        }}
      </style>
    </head>
    <body>
      <h1>Scan Reports</h1>
      <h2>Nikto Scan</h2>
      <ul>
        <li><a href="nikto_scan.html">View Nikto Scan Report</a></li>
      </ul>
      <h2>SSLScan</h2>
      <ul>
        <li><a href="sslscan_report.html">View SSLScan Report</a></li>
      </ul>
    </body>
    </html>
    """
    
    # Format the string placeholders with the folder paths
    index_html_output = index_html_output.format(reports_folder_path=reports_folder_path, folder_path=folder_path)
    
    # Write the HTML output to index.html in the original folder
    with open(f"{folder_path}/index.html", "w") as file:
        file.write(index_html_output)
    
    
    # Create reports.md with GitHack links
    reports_md_output = f"# Scan Reports\n\n"
    reports_md_output += f"## All Reports\n\n- [View All Reports](https://raw.githack.com/{reports_folder_path}/index.html)\n"
    reports_md_output += f"### Nikto Scan\n\n- [View Nikto Scan Report](https://raw.githack.com/{reports_folder_path}/nikto_scan.html)\n"
    reports_md_output += f"### SSLScan\n\n- [View SSLScan Report](https://raw.githack.com/{reports_folder_path}/sslscan_report.html)\n"
    
    # Write the Markdown output to reports.md
    with open(f"{folder_path}/reports.md", "w") as file:
        file.write(reports_md_output)
    ```
    
- Create clear-old-tests.py
  
  - Checks to see if there are more than three folders of test results and if there are it removes the oldest folder and its contents.
    
  - Also checks to see if all folders are tests on the current release version to avoid pushing test results for older versions to a new release version branch. It deletes old version test results, but they are still stored on the branch for the older version.
    
  - You can adjust how many tests are stored by changing the number in line 31
    
  - ```python
    import sys
    import os
    import shutil
    from datetime import datetime, timedelta
    
    # Define the directory where the folders are located
    directory = '/path/to/folders'
    
    # Get the release version from the command-line argument
    release_version = sys.argv[1]
    
    # Get a list of all folders in the directory
    folders = [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]
    
    # Filter out folders that don't match the current release version
    folders_to_remove = [f for f in folders if not f.endswith(release_version)]
    
    # Remove folders that don't match the current release version
    for folder_to_remove in folders_to_remove:
        folder_path = os.path.join(directory, folder_to_remove)
        shutil.rmtree(folder_path)
        print(f"The folder '{folder_to_remove}' has been removed.")
    
    # Get the remaining list of folders
    folders = [f for f in os.listdir(directory) if os.path.isdir(os.path.join(directory, f))]
    
    # Sort the folders based on their creation date
    folders.sort(key=lambda x: datetime.strptime(x[:10], "%Y-%m-%d"))
    
    # Check if there are more than three folders
    if len(folders) > 3:
        # Determine the folder to be removed (oldest one)
        folder_to_remove = folders[0]
    
        # Construct the full path of the folder to be removed
        folder_path = os.path.join(directory, folder_to_remove)
    
        # Remove the folder and its contents
        shutil.rmtree(folder_path)
    
        print(f"The folder '{folder_to_remove}' has been removed.")
    else:
        print("No action required. Less than three folders found.")
    ```
    

### GitHub Actions Workflow

- Self-hosted runner vs GitHub-hosted runner
  
  - [GitHub workflow comparison - Google Sheets](https://docs.google.com/spreadsheets/d/1J_7-H9Bh8ZL3v7pxPm6oOxr9PGzLZvxDSgxOdWJv1Xo/edit?usp=sharing)
  - In addition to the comparisons in the google sheet, a self-hosted runner allows you to have python scripts that are stored on the server that can be used to help generate reports and clean up old reports

#### Workflow Breakdown

```yaml
name: pentest

on:
# workflow_dispatch:
# cronjob will be used when it is fully set up and complete
  schedule:
    - cron: '0 3 1,15 * *'
    - cron: '0 2 * * 0'
```

- At the top of your yml file, you will specify the name of the Action and what the conditions are for the workflow to run. workflow_dispatch allows you to run the yaml file on command, which is helpful for development when you are actively making changes and need to test your code. However, once it is ready to deploy, you can have it run on a schedule with a cronjob such as above, where it runs at 3:00 AM on the 1st and 15th of every month. There is also another schedule that will be used for a second job within the workflow that will run at 2:00 AM every Sunday, which will be used to make sure that the self-hosted runner does not terminate from not being used after 14 days.
  
  - If you need help creating a cron schedule: [https://crontab.guru/](https://crontab.guru/)

```yaml
jobs:
#  start:
#    runs-on: ubuntu-latest
#    
#    steps:
#      - name: Start EC2 Instance
#        run: |
#          aws ec2 start-instances --instance-ids ${{secrets.AWS_EC2_INSTANCE_ID }}
#        env:
#          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
#          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION }}

  scanner:
#    needs: start
    if: (github.event.schedule == '0 3 1,15 * *') || (github.event.workflow_dispatch)
    runs-on: [self-hosted, linux, x64, ubuntu-server]
```

- In my workflow, I only use one job, but jobs allow for the workflow to use multiple runners at the same time or you can connect the jobs using "needs: {previous job name}" so that it only runs once the specified job has been completed.
- The commented code for the job "start" is if you wanted to connect your workflow to your AWS account so that it could start and stop your EC2 instance if necessary, but we decided that this was not necessary for this project so it is commented out
- The if statement checks to see if the workflow is running from either the first schedule or manually from workflow_dispatch and if it is, then it will run the scanner job.
- The scanner job runs on our self-hosted runner on our Ubuntu EC2 instance with the default tags of "self-hosted, linux, x64" as well as the custom tag "ubuntu-server" to be more specific in case other self-hosted runners are active

```yaml
    steps:
      - name: Start dotCMS with docker
        id: start-dotcms
        run: |
          docker-compose down && docker-compose up -d
```

- The first step in the scanner job is to start dotCMS with docker. In case docker did not shut down properly previously, it runs "docker-compose down" to ensure that it was shut down properly before starting it up with "docker-compose up." The tag "-d" allows for docker to run in the background so that we can continue to use the runner, otherwise you would have to create another self-hosted runner to run everything else, which overcomplicates the program.

```yaml
      - name: Install updates
        run: sudo apt-get update

      - name: Pull dotCMS/core-test-results repository
        run: |
          git config pull.rebase false
          git remote set-url origin git@github.com:dotCMS/core-test-results.git
          git pull origin master
        working-directory: /home/ubuntu/core-test-results

      - name: Get latest release version
        id: get-latest-release
        run: |
          releases=$(curl -s "https://api.github.com/repos/dotCMS/core/releases")
          release_version=$(echo "$releases" | jq -r '.[].tag_name' | sort -rV | head -n 1 | sed 's/^v//')
          formatted_version="release-$release_version"
          echo "Latest release version: $formatted_version"
          echo "release_version=$formatted_version" >> $GITHUB_ENV
```

- dotCMS will take a few minutes to start up with docker, so these steps are run while it is starting up to cut down the run time of the workflow.
  
  - First, we install updates to ensure that we are using the latest version of the tools to get the best results.
    
  - The next step is to pull the core-test-results repository using ssh.
    
  - The final step that is run while dotCMS is starting up is to get the latest release version of dotCMS. This workflow runs the latest agile release of dotCMS through docker, so this step finds the latest agile release version from the releases page on the dotCMS/core repository. It is then formatted as "release-XX.XX"
    

```yaml
      - name: Check if web server is running
        run: |
          server_status=$(wget --spider -S http://localhost:8082 2>&1 | grep "HTTP/" | awk '{print $2}')
          if [[ "$server_status" == "200" ]]; then
            echo "Web server is running"
          else
            echo "Web server is not running"
            exit 1
          fi
```

- This step checks to see if dotCMS is fully up and running using wget. The wget command gets the HTTP response headers from the server until it returns "200," meaning that the server is running. In previous versions of the workflow, a sleep command was used to wait until the server was running, but this current method is more reliable and only takes as much time as needed for the server to start up.

```yaml
      - name: Run nikto scan
        run: |
          report_dir="/home/ubuntu/core-test-results/pentest/$(date +'%Y-%m-%d')-$release_version"
          mkdir -p "$report_dir"
          nikto -h localhost:8082 |& tee "$report_dir/report.txt"
      
      - name: Run sslscan
        run: |
          report_dir="/home/ubuntu/test-results/pentest/$(date +'%Y-%m-%d')-$release_version"
          mkdir -p "$report_dir"
          sslscan localhost:8443 |& tee "$report_dir/sslscan_report.txt"
```

- In this step, we are running a scan with a tool called nikto. Nikto is a free software command-line vulnerability scanner that scans web servers for dangerous files/CGIs, outdated server software and other problems. The scan that is being run is just the default scan on the localhost and the results are sent to "report.txt" in the pentest folder in the core-test-results repository. Within the pentest folder they are placed into a folder with the current date and release version to distinguish when the tests were ran and what branch they should be in.
- The tool called SSLScan is also run, which tests SSL/TLS enabled services to discover supported cipher suites. This report is generated the same way as the nikto scan report and the output is in the same directory.

```yaml
      - name: Run htmlreport.py
        run: python3 /home/ubuntu/htmlreport.py $release_version

      - name: Run clear-old-tests.py
        run: python3 /home/ubuntu/clear-old-tests.py $release_version

      - name: Stop dotCMS
        run: docker-compose down
        working-directory: /home/ubuntu
```

- These steps run the two python files that were provided under the "Setup on Server" section of the documentation.
  
  - htmlreport.py generates an organized html report of the tests that have been run and places it in the proper folder.
    
  - clear-old-tests.py only keeps the three most recent reports (including the one that has just been generated) and removes any reports that are not from the current release version. This is done to avoid storing test results from older versions under newer versions and to avoid storing too many outdated results.
    
- The third step here stops the dotCMS docker instance as it is no longer needed using "docker-compose down" to properly shut down the containers
  

```yaml
      - name: Switch to release branch
        run: |
          branch_name="${{ env.release_version }}"
          git fetch origin "$branch_name" && git checkout "$branch_name" || git checkout -b "$branch_name"
        working-directory: /home/ubuntu/core-test-results

      - name: Add files and commit changes
        run: |
          git add .
          git commit -m "Add test results for release ${{ env.release_version }}"
        working-directory: /home/ubuntu/core-test-results

      - name: Push changes to dotCMS/core-test-results repository
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.SECRET_PENTEST_TOKEN }}
          branch: ${{ env.release_version }}
          force: true
          directory: /home/ubuntu/core-test-results/
          repository: dotCMS/core-test-results
```

- In these last few steps, we switch to the release branch, where the results will then be added and pushed. This is not creating a new branch as there is already an existing branch for the latest agile release as it is created upon release.

```yaml
  maintenance:
    if: github.event.schedule == '0 2 * * 0'
    runs-on: [self-hosted, linux, x64, ubuntu-server]

    steps:
      - name: Connect to self-hosted runner
        run: echo "Connecting to self-hosted runner to avoid termination due to inactivity"
```

- This job runs on the same self-hosted runner as the scanner job, just on a different schedule that is more frequent. This is used just to make sure that the self-hosted runner is started and has activity so that it does not automatically terminate after 14 days of inactivity

```yaml
#  pull_request:
#    needs: scanner
#    runs-on: [self-hosted, linux, x64, ubuntu-server]
#    
#    steps:
#
#      - name: Create pull request
#        run: |
#          branch_name="pentest-$(date +'%Y%m%d')"
#          pr_title="Pentest Results"
#          pr_body="This is an automated pull request with the latest pentest results. Please review the attached report."
#          git add test-results/*
#          git commit -m "Add pentest report"
#          git push origin "$branch_name"
#          curl -X POST \
#            -H "Authorization: token ${{ secrets.PERSONAL_ACCESS_TOKEN }}" \
#            -H "Accept: application/vnd.github.v3+json" \
#            https://api.github.com/repos/TommyB13/RunnerTest/pulls \
#            -d '{
#              "title": "'"$pr_title"'",
#              "body": "'"$pr_body"'",
#              "head": "'"$branch_name"'",
#              "base": "main"
#            }'
#        env:
#          PERSONAL_ACCESS_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
#        working-directory: /home/ubuntu/RunnerTest
#
#          repo: dotCMS/core-test-results
#
#      - name: Stop AWS EC2
#        run: |
#          aws ec2 stop-instances --instance-ids ${{secrets.AWS_EC2_INSTANCE_ID }}
#        env:
#          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
#          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION }}
```

- None of this code is implemented in the final version of the workflow, but it remains commented out at the end of the code in case future implementations of the workflow wish to have pull request functionality or the ability to stop the AWS EC2 instance.
